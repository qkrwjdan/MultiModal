{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae5067b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import transformers\n",
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fa90630",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ff007cc33331>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasets_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasets_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Workspace/MultiModal/venv/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/MultiModal/venv/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/MultiModal/venv/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/MultiModal/venv/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/MultiModal/venv/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "datasets_path = os.path.join(os.getcwd(),\"datasets\",\"iemocap_text\")\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for dataset in os.listdir(datasets_path):\n",
    "    path = os.path.join(datasets_path,dataset)\n",
    "    df = pd.concat([df,pd.read_csv(path)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5b2e16c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Clip_Name', 'text', 'Label', 'Use'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c84e1aa63305>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Clip_Name\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Label\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Use\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/MultiModal/venv/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2910\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2911\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2912\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2914\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/MultiModal/venv/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/MultiModal/venv/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1298\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m             \u001b[0;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['Clip_Name', 'text', 'Label', 'Use'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "df = df[[\"Clip_Name\",\"text\",\"Label\",\"Use\"]]\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74252448",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelEncoder = {\"Negative\" : 0, \"Neutral\" : 1, \"Positive\" : 2}\n",
    "\n",
    "df[\"Label\"] = [labelEncoder[label] for label in df[\"Label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4eccca93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clip_Name</th>\n",
       "      <th>text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Use</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ses02F_impro01_F000</td>\n",
       "      <td>Hi. Excuse me. Um, I'd like to put in this app...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ses02F_impro01_F018</td>\n",
       "      <td>Well, why didn't the D.M.V. put that you neede...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ses02F_impro01_F019</td>\n",
       "      <td>Yeah, but your birth certificate--I mean, who ...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ses02F_impro01_F020</td>\n",
       "      <td>With your driver's license and your passport. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ses02F_impro01_F021</td>\n",
       "      <td>Who--you always use your driver's license. I m...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>Ses03M_script03_2_M040</td>\n",
       "      <td>Turn it--Turn it off.</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>Ses03M_script03_2_M041</td>\n",
       "      <td>Very amusing indeed.</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>Ses03M_script03_2_M042</td>\n",
       "      <td>You know what? You're a vile, little, evil-min...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>Ses03M_script03_2_M043</td>\n",
       "      <td>You're not going nowhere. No you're not.</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>Ses03M_script03_2_M044</td>\n",
       "      <td>Just shut up.</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1924 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Clip_Name  \\\n",
       "0       Ses02F_impro01_F000   \n",
       "1       Ses02F_impro01_F018   \n",
       "2       Ses02F_impro01_F019   \n",
       "3       Ses02F_impro01_F020   \n",
       "4       Ses02F_impro01_F021   \n",
       "..                      ...   \n",
       "580  Ses03M_script03_2_M040   \n",
       "581  Ses03M_script03_2_M041   \n",
       "582  Ses03M_script03_2_M042   \n",
       "583  Ses03M_script03_2_M043   \n",
       "584  Ses03M_script03_2_M044   \n",
       "\n",
       "                                                  text  Label    Use  \n",
       "0    Hi. Excuse me. Um, I'd like to put in this app...      1  train  \n",
       "1    Well, why didn't the D.M.V. put that you neede...      0   test  \n",
       "2    Yeah, but your birth certificate--I mean, who ...      0  train  \n",
       "3    With your driver's license and your passport. ...      0  train  \n",
       "4    Who--you always use your driver's license. I m...      0  train  \n",
       "..                                                 ...    ...    ...  \n",
       "580                              Turn it--Turn it off.      0  train  \n",
       "581                               Very amusing indeed.      0  train  \n",
       "582  You know what? You're a vile, little, evil-min...      0  train  \n",
       "583           You're not going nowhere. No you're not.      0  train  \n",
       "584                                      Just shut up.      0   test  \n",
       "\n",
       "[1924 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75893e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce GTX 1080 Ti\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f3320296c00>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 19\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "else: \n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f427c65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df[df[\"Use\"] == \"train\"]\n",
    "val_data = df[df[\"Use\"] == \"validation\"]\n",
    "test_data = df[df[\"Use\"] == \"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd8b131f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'roberta-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59c89875",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = RobertaModel.from_pretrained(MODEL_NAME)\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3ce0894",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = train_data[\"text\"].tolist()\n",
    "val_text = val_data[\"text\"].tolist()\n",
    "test_text = test_data[\"text\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fc31064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get length of all the messages in the train set\n",
    "seq_len = [len(i.split()) for i in train_text]\n",
    "\n",
    "pd.Series(seq_len).hist(bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d0aeaaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/park/Workspace/MultiModal/venv/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 30\n",
    "\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_data[\"text\"].tolist(),\n",
    "    max_length = MAX_LEN,\n",
    "    pad_to_max_length = True,\n",
    "    truncation = True\n",
    ")\n",
    "\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    val_data[\"text\"].tolist(),\n",
    "    max_length = MAX_LEN,\n",
    "    pad_to_max_length = True,\n",
    "    truncation = True\n",
    ")\n",
    "\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    test_data[\"text\"].tolist(),\n",
    "    max_length = MAX_LEN,\n",
    "    pad_to_max_length = True,\n",
    "    truncation = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c43bee07",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_data[\"Label\"].tolist())\n",
    "\n",
    "val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor(val_data[\"Label\"].tolist())\n",
    "\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(test_data[\"Label\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21833d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "378\n"
     ]
    }
   ],
   "source": [
    "print(len(train_seq[0]))\n",
    "print(len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f4d4bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = TensorDataset(train_seq, train_mask, train_y)\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(train_dataset, sampler = train_sampler, batch_size = batch_size)\n",
    "\n",
    "val_dataset = TensorDataset(val_seq, val_mask, val_y)\n",
    "val_sampler = RandomSampler(val_dataset)\n",
    "val_dataloader = DataLoader(val_dataset, sampler = val_sampler, batch_size = batch_size)\n",
    "\n",
    "test_dataset = TensorDataset(test_seq, test_mask, test_y)\n",
    "test_sampler = RandomSampler(test_dataset)\n",
    "test_dataloader = DataLoader(test_dataset, sampler = test_sampler, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78b52dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "    \n",
    "    def __init__(self, bert):\n",
    "        super(BERT_Arch, self).__init__()\n",
    "        \n",
    "        self.bert = bert\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(768,512)\n",
    "        self.fc2 = nn.Linear(512,3)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, sent_id, mask):\n",
    "        \n",
    "        ret = self.bert(sent_id, attention_mask = mask).pooler_output\n",
    "#         ret = self.bert(sent_id, attention_mask = mask)\n",
    "        \n",
    "#         print(ret)\n",
    "        \n",
    "        x = self.fc1(ret)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "#         print(x.size())\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94b5fa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERT_Arch(bert)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d9180c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c50e7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class Weight :  [0.64360242 1.17670683 1.67668097]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/park/Workspace/MultiModal/venv/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass classes=[0 1 2], y=[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1, 0, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 2, 2, 2, 2, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 2, 2, 2, 1, 2, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 2, 1, 2, 2, 1, 0, 1, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 0, 2, 0, 1, 1, 0, 0, 0, 0, 2, 2, 2, 0, 1, 1, 2, 0, 0, 1, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 2, 1, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 2, 2, 0, 2, 2, 2, 2, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 2, 1, 1, 1, 1, 1, 0, 0, 2, 2, 2, 0, 2, 0, 0, 0, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 0, 0, 0, 2, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight('balanced', np.unique(train_data[\"Label\"].tolist()), train_data[\"Label\"].tolist())\n",
    "\n",
    "print(\"class Weight : \",class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "381a6716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = torch.tensor(class_weights, dtype = torch.float)\n",
    "# weights = weights.to(device)\n",
    "\n",
    "cross_entropy = nn.NLLLoss()\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42b16dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    \n",
    "    total_loss, total_acc = 0, 0\n",
    "    \n",
    "    total_preds = []\n",
    "    \n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        \n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            print('Batch {:>5,} of {:>5,}.'.format(step, len(train_dataloader)))\n",
    "        \n",
    "        batch = [r.to(device) for r in batch]\n",
    "        sent_id, mask, labels = batch\n",
    "        \n",
    "        model.zero_grad()\n",
    "        preds = model(sent_id, mask)\n",
    "        \n",
    "        # how can i to draw graph using loss?\n",
    "        loss = cross_entropy(preds, labels)\n",
    "        total_loss = total_loss + loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        preds = preds.detach().cpu().numpy()\n",
    "        \n",
    "        total_preds.append(preds)\n",
    "    \n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    \n",
    "    total_preds = np.concatenate(total_preds, axis = 0)\n",
    "    \n",
    "    return avg_loss, total_preds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee2d53ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    print(\"\\n Evaluating...\")\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    total_loss, total_acc = 0, 0\n",
    "    \n",
    "    total_preds = []\n",
    "    \n",
    "    for step, batch in enumerate(val_dataloader):\n",
    "        \n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            print('Batch {:>5,} of {:>5,}'.format(step, len(val_dataloader)))\n",
    "            \n",
    "        batch = [t.to(device) for t in batch]\n",
    "        \n",
    "        sent_id, mask, labels = batch\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            preds = model(sent_id, mask)\n",
    "            loss = cross_entropy(preds, labels)\n",
    "            total_loss = total_loss + loss.item()\n",
    "            \n",
    "            preds = preds.detach().cpu().numpy()\n",
    "            \n",
    "            total_preds.append(preds)\n",
    "            \n",
    "    avg_loss = total_loss / len(val_dataloader)\n",
    "    \n",
    "    total_preds = np.concatenate(total_preds, axis = 0)\n",
    "    \n",
    "    return avg_loss, total_preds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9bab75c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch1 / 10\n",
      "\n",
      " Evaluating...\n",
      "\n",
      "Training Loss: 1.077\n",
      "Test Loss: 1.038\n",
      "\n",
      " Epoch2 / 10\n",
      "\n",
      " Evaluating...\n",
      "\n",
      "Training Loss: 1.019\n",
      "Test Loss: 0.994\n",
      "\n",
      " Epoch3 / 10\n",
      "\n",
      " Evaluating...\n",
      "\n",
      "Training Loss: 0.997\n",
      "Test Loss: 0.964\n",
      "\n",
      " Epoch4 / 10\n",
      "\n",
      " Evaluating...\n",
      "\n",
      "Training Loss: 0.951\n",
      "Test Loss: 0.913\n",
      "\n",
      " Epoch5 / 10\n",
      "\n",
      " Evaluating...\n",
      "\n",
      "Training Loss: 0.857\n",
      "Test Loss: 0.869\n",
      "\n",
      " Epoch6 / 10\n",
      "\n",
      " Evaluating...\n",
      "\n",
      "Training Loss: 0.755\n",
      "Test Loss: 0.861\n",
      "\n",
      " Epoch7 / 10\n",
      "\n",
      " Evaluating...\n",
      "\n",
      "Training Loss: 0.663\n",
      "Test Loss: 0.819\n",
      "\n",
      " Epoch8 / 10\n",
      "\n",
      " Evaluating...\n",
      "\n",
      "Training Loss: 0.564\n",
      "Test Loss: 0.855\n",
      "\n",
      " Epoch9 / 10\n",
      "\n",
      " Evaluating...\n",
      "\n",
      "Training Loss: 0.497\n",
      "Test Loss: 0.900\n",
      "\n",
      " Epoch10 / 10\n",
      "\n",
      " Evaluating...\n",
      "\n",
      "Training Loss: 0.410\n",
      "Test Loss: 0.885\n"
     ]
    }
   ],
   "source": [
    "best_valid_loss = float('inf')\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    print('\\n Epoch{:} / {:}'.format(epoch + 1, epochs))\n",
    "    \n",
    "    train_loss, _ = train()\n",
    "    \n",
    "    val_loss, _ = evaluate()\n",
    "    \n",
    "    if val_loss < best_valid_loss:\n",
    "        best_valid_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'models/emocap_3class_rbt_Test.pt')\n",
    "        \n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Test Loss: {val_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6e7ac80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'models/emocap_3class_rbt_Test.pt'\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611c3a19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9ccf550",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    preds = model(val_seq.to(device),val_mask.to(device))\n",
    "    preds = preds.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f93e1b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.80      0.76       198\n",
      "           1       0.55      0.59      0.57        99\n",
      "           2       0.65      0.42      0.51        77\n",
      "\n",
      "    accuracy                           0.66       374\n",
      "   macro avg       0.64      0.60      0.61       374\n",
      "weighted avg       0.66      0.66      0.66       374\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = np.argmax(preds, axis = 1)\n",
    "print(classification_report(val_y,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bdd7033a",
   "metadata": {},
   "outputs": [],
   "source": [
    "testDf = pd.read_csv(os.path.join(os.getcwd(),\"datasets\",\"session1_master.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "63a80b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "testDf = testDf[testDf[\"Use\"] ==  \"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6cf088c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "testDf = testDf[[\"Clip_Name\",\"text\",\"Label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e5a64fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "testDf[\"Label\"] = [labelEncoder[label] for label in testDf[\"Label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3fad7da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    testDf[\"text\"].tolist(),\n",
    "    max_length = MAX_LEN,\n",
    "    pad_to_max_length = True,\n",
    "    truncation = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "44737699",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(testDf[\"Label\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "62d236a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    preds = model(test_seq.to(device),test_mask.to(device))\n",
    "    preds = preds.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "32c7a06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.75      0.73        84\n",
      "           1       0.52      0.63      0.57        46\n",
      "           2       0.58      0.26      0.36        27\n",
      "\n",
      "    accuracy                           0.63       157\n",
      "   macro avg       0.60      0.55      0.55       157\n",
      "weighted avg       0.63      0.63      0.62       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = np.argmax(preds, axis = 1)\n",
    "print(classification_report(test_y,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1677f17b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
